# Ecoinformatics

## Ecoinformatics

### Michener *et al*, 2001

*"Defining and unraveling biocomplexity"* [@michener2001defining]

**Key contribution:** This study's primary contribution to the literature is a formal definition of biocomplexity, and an investigation of its emergence within the scientific disciplines. The article primarily discusses:

  1. Defining biocomplexity
  2. Examining the characteristics of biocomplexity
  3. Speculating on the future of biocomplexity
  
*Biocomplexity* - "properties emerging from the interplay of behavioral, biological, chemical, physical, and social interactions that affect, sustain, or are modified by living organisms, including humans," as defined by [@michener2001defining]
  
**Key notes: **

  - Biocomplexity exists in contrast to the Popperian type of reductionalist science (causality & falsification), and recognizes that reduced causal mechanisms often are not robust within real-world situations
    - "myriad confounding factors operating at different temporal and spatial scales"
  - Two features of "biocomplexity"
    1. biocomplexity occurs as temporal, spatial and conceptual boundaries are broken-down and worked across
    2. emergent & unexpected properties may (or likely will) arise in response to biocomplexity

**Characteristics of "biocomplexity":**

  1. Relevant for a wide range of organisms; from microbial to megafauna (including humans)
  2. Relevant for a wide range of environments
  3. Reflected in nonlinear, chaotic, or unpredictable behaviors -- which likely necessitates sophisticated and innovative quantitative procedures
  4. Likely to span many hierarchical levels as well as across multiples scales in time and space
    
**Key research trajectories for ecology (as posed by Thompson 2001):**

  1. "Dynamics of coalescence in complex communities" - how do environmental constraints and species availability result in current complex ecological communities
  2. "Ecological memory" - how do past events & conditions influence current ecological structure and conditions
  3. "Emergent properties" - examining whether the first principles of "hard" sciences can predict composition, structure & function
  4. "Ecological topology" - identifying "rules" that occur over different scales of time and space, and examining how they interact to produce ecosystems

**Further reading:**

  1. [@thompson2001frontiers] - Frontiers of ecology: As ecological research enters a new era of collaboration, integration, and technological sophistication, four frontiers (listed above) seem paramount for understanding how biological and physical processes interact over multiple spatial and temporal scales to shape the Earth's biodiversity

### Jones *et al*, 2006

*"The new bioinformatics: Integrating ecological data from the gene to the biosphere"* [@jones2006new]

**Key contribution:** This paper makes the case for "locating, accessing and integrating" data within ecology. They provide examples of the successes associated with doing so in alternative fields (genetics), and make a case for the need within ecology. They also outline vertically integrated databases (data warehouses) versus metadata-driven databases (data collections), and the relative pros/cons of the two.

**Examples of metadata and data collections in ecology:**

```{r, echo=FALSE}
knitr::include_graphics(rep("images/jones2006AREES.bmp"))
```

**Key notes**: Some relevant points from the article:

  - A focus on "experimental" design and testing of multiple hypotheses makes ecological data inherently heterogeneous.
  - Ecoinformatics importance is housed in ability to "allow a broader perspective over time and space, and across many disciplines, than is possible from on or a few studies," and in allowing data to be reused for questions that may emerge in the future.
    - Would appear to be well-suited to address questions of biocomplexity
  - Current standard for storing of data is in heterogeneous spreadsheets
  - *Data warehouses (vertically-integrated)* - databases that coalesce data from many investigators, but focus on one theme and are searchable often through an online interface 
    - Often represents a "least-common denominator" approach in that they are less complex than original dataset
    - Examples: GenBank, VegBank or TreeBase
  - *Data collections (metadata-driven)* - collection of datasets that are loosely structured together by well-crafted metadata. Some advantages are:
      1. Data of disparate types can be housed within a single location
      2. Focuses on project-level data and thus is familiar to researchers
      3. Metadata often more detailed
      4. Metadata often more precise and thus can be used in search functions
  - *Metadata standards* - "consistent and rigorous sets of definitions for metadata categories that are broadly adopted by a research community." Several examples exist within ecology:
      1. Ecological Metadata Language (EML)
      2. Biological Data Profile (BDP)
      3. Geographic Markup Language (GML)
      4. Knowledge Network for Biocomplexity (KNB) - a metadata-drive repo that provides mappings from EML to BDP (but not from BDP to EML as of time of article publication)
  - *Data islands* - data derived from researchers working on disparate, autonomous topics that focus on specific, predetermined hypotheses
    - Often subject to entrenched domain-specific vocabularies and also assumptions; ontologies may be a way of resolving this limitation
  - *Ontologies* - well-defined concepts or terms that have precise meanings within a specific domain or field, as well as formal mappings of how the terms interrelate
    - *Science Environment for Ecological Knowledge (SEEK)* - one example of a system developing ontologies within ecology

**Further reading:**

  1. Look into metadata languages (e.g., EML)
  2. Look into some of the earlier work on databases by Michener

### Michener, 2006

*"Meta-information concepts for ecological data management"* [@michener2006meta]

**Definitions:**

  - *Metadata* - information about data, i.e. higher level descriptions of data
  - *Meta-information* - information derived from subsequent data processing and analyses; are these data products?

**Key contribution:** Michener outlines some of the key criteria, challenges and opportunities for metadata within an ecological context.

**Notes on metadata: **

Some benefits of metadata include:

  1. Longevity of the data is greatly increased
  2. Reuse of the data both by the original researcher and others is facilitated
  3. Well-documented data may be used to expand scale of ecological inquiry
  
The primary functionality of metadata is:

  1. Supports data discovery (most basic level)
  2. Facilitates the acquisition and use of data by humans (requires additional metadata)
  3. Enables automatic discovery, ingestion and analysis of data (requires more sophisticated metadata), which needs:
    - research context (hypothesis, study site, experimental design, etc.)
    - status of dataset
    - physical structure of dataset
    - info to facilitate use and comprehension
      
**Ecological Metadata Language (EML):**

  - EML is a standard for metadata that provides structure that supports automated functions of metadata listed above and is implemented in eXtensible Markup Language (XML)
  - Organized into modules, such as "dataset", "access", "physical", "party coverage", "project", "methods", "datatable", "attribute", and "physical"
    - Additional info at [ecoinformatics.org](http://ecoinformatics.org/)
  
### Bekker *et al*, 2007

*"Long term datasets: From descriptive to prescriptive data using ecoinformatics"* [@bekker2007long]

**Key contribution:** This is the lead article to a special issue in *Journal of Vegetation Science* that focuses on ecoinformatics driven approaches to understanding complexity within vegetation systems. The article is less informative in its own right as much as a good pointer to other key studies working with vegetation science and ecoinformatics. It appears to be one of the earliest applications of ecoinformatics to vegetation science.

**Further reading:**

  1. Le Duc, 2007 - A database application for long-term ecological field experiments
  2. Peacock, 2007 - The RAINFOR database, for monitoring forest biomass and dynamics
  

### Hale & Hollister, 2009

*"Beyond data management: How ecoinformatics can benefit environmental monitoring programs"* [@hale2009beyond]

**Key contribution: ** This is a less seminal study. They describe the relevance of ecoinformatics for environmental monitoring, but do not go much beyond some of the other pieces on ecoinformatics and its relevance for ecology. Some relevant points that stood out to me:

  - Standardization of taxonomic classes may be facilitated by ecoinformatics and application of ontologies in ecoinformatics
  - Establishing standards and protocols can help in synthesizing studies and results across time and space

**Note: ** Likely better to focus on other studies within the literature than this one as they don't bring up many points beyond those expressed in more seminal works.

### Feller *et al*, 2010

*"Biocomplexity in mangrove ecosystems"* [@feller2010biocomplexity]

**Key contribution:** Aim to elucidate the factors playing in at different hierarchical levels in mangrove ecosystems (biocomplexity). They use emergent properties (which they define as "patterns or processes that occur at multiple hierarchical levels within ecosystems") to examine underlying ecological processes within mangroves.

Biocomplexity appears to be thinking of ecology through a hierarchical lens, in which processes that exist at the "hard science" level (physics, chemistry, etc.) result in ecological processes > functions > services.

**Key findings:** The article doesn't differ much from other reviews of controls on mangrove processes, apart from the structure in which they examine:

  1. Controls of emergent properties (namely specializations for variable salinity, flooding and nutrient availability)
    - e.g., salinity tolerance, flooding tolerance, reproductive traits/regeneration, nutrient availability
    - perhaps analogous to "ecosystem processes"
  2. Collective properties of forests (e.g., zonation, productivity, nutrient cycling, food webs)
    - perhaps analogous to "functions"
  3. Emergent/collective properties of ecosystems & landscapes (e.g., habitat stability & connectivity of ecosystems)
    - perhaps analogous to "services" or "benefits"

*Emergent properties* - concept that the whole is greater than the sum of its parts when examining ecological phenomena and the underlying processes that drive them. Emergent properties can exist at any scale, and may build upon themselves (e.g., morphology and physico-chemical conditions leading to ecophysiology (emergent property) which then leads to spatial assemblages (2^nd^ emergent property), etc.). It may be helpful to think of different emergent properties at different scales of time and space.

Three primary characteristics of emergent properties exist:

  1. Emergent properties are not simply the sum of their parts
  2. Emergent properties exist as a type that is different from their underlying components
  3. They cannot be easily predicted from individual components

Examples of emergent properties within mangroves are ecophysiological traits (as listed above) that emerge from the interaction between biochemical and morphological traits with environmental factors.

Individual Based Models (IBMs) are discussed as useful though limited tools for examining biocomplexity within mangroves, but note that there is relatively little work in this field to date. See section \@ref(chentwilley1998) for an example of using IBMs within mangroves.

```{r, echo=FALSE}
knitr::include_graphics(rep("images/feller2010ARMS.bmp"))
```

**Relevance to research:**

  1. Are IBMs relevant for research questions at hand?


### Michener & Jones, 2012

*"Ecoinformatics: Supporting ecology as a data intensive science"* [@michener2012ecoinformatics]

**Key contribution: ** This is a seminal study on the relevance of ecoinformatics written by two of the leading thinkers in the field.

**Key notes: ** Several key notes from the study are:

  - The authors describe the "data life cycle,"" with 8 steps that do not necessarily occur in sequential order and depend upon the analysis and research question at hand.
  - The steps are:
    1. *Plan* - derive a data management plan that is often a living document as needs and uses for data will change over time
    2. *Collect* - there are highly variable mechanisms under which this occur given the vast amount of data types and collecting methods that exist; standardization in collection procedures is key for synthesizing data at later times
    3. *Assure* - measures taken to ensure data quality both before and after collection of the data; may consist of standardization of codes, units or metadata (e.g., using EML)
    4. *Describe* - sufficiently describing the data via metadata (who, what, when, where, why)
    5. *Preserve* - depositing of data in a repository such that they may be verified, maintained and accessed through time
    6. *Discover* - identifying appropriate data for research question of interest; double-edged sword in that you can get millions of hits or alternatively have tons of distinct data sources that exist only on disparate, local machines. DataONE is one such tool that drills down into data to identify datasets of actual interest; this is where ontologies come into play
    7. *Integrate* - understanding methodological differences, transforming to common representations and converting and recoding data to comparable semantics
    8. *Analyze* - reproducibility in analysis, with a particular focus on scientific workflows

*DataONE:* DataONE is a research platform that seeks to support the entire data life cycle, as well as integrate many different forms of data. There are three principle components:

  1. Member Nodes - contribute data, computing resources and services (e.g., data repositories, universities, computing centers)
  2. Coordinating Nodes - support network-wide services such as indexing, replication, and interactability of Member Nodes
  3. Investigator Toolkit - tools for researchers to employ in all steps of the data life cycle
    
**Schematic of the data life cycle:**

```{r, echo=FALSE}
knitr::include_graphics(rep("images/michenerjones2012.bmp"))
```

### Soranno, 2014 {#sorrano2014}

*"Cross-scale interactions: Quantifying multi-scaled cause -- effect relationships in macrosystems"* [@soranno2014cross]


### Ruegg, 2014 {#ruegg2014}

*"Completing the data life cycle: Using information management in macrosystems ecology research"* [@ruegg2014completing]


## Ontologies

### Williams, 2006 {#williams2006}

*"Ontologies for ecoinformatics"* [@williams2006ontologies]

**Key contribution:** This is an early piece that gives an overview of what purpose ontologies may serve within ecology. They discuss it in particular relation to food webs within ecology, which are inherently complex with multiple definitions or system-specific interpretations for terms.

**Key notes: ** Ontologies should be employed to describe the following characteristics of a dataset:

  1. Where, when and by who the data are collected
  2. A description of what was observed, including identity and traits of the organism
  3. Sampling protocol, including collection procedures and associated experimental manipulations
  
The architecture of the ontology can be designed intelligently such that the ontology is extensible, and allows for both system-specific interpretations as well as across-system relationships. For example, they discuss the importance of separating "entities" and "traits".

The piece by Madin, 2008 (see Section \@ref(madin2008)) provides a more comprehensive overview of ontologies within ecology and should be referred to in conjunction with this piece.

### Madin, 2007 {#madin2007}

*"An ontology for describing and synthesizing ecological observation data"* [@madin2007ontology]



### Madin, 2008 {#madin2008}

*"Advancing ecological research with ontologies"* [@madin2008advancing]

**Key significance:** This article gives an overview of ontologies in ecology, with particular focus on:

  1. What issue they are capable of resolving -- i.e., integration of heterogeneous data
  2. What ontologies are and the forms they take
  3. Ongoing efforts to advance ontologies within ecology

**Ontologies** provide a formal mechanism for defining terms and their relationships, and can improve the location, interpretation and integration of data based on its inherent meaning."

**The issue:** Lack of critical consideration of "concepts" within ecology complicates interpretation and synthesis of findings, as well as the location and reuse of existing datasets.

**The solution:** Ontologies provide a formal framework for establishing concepts within a discipline, and can resolve some of the issues that arise from multiple or nuanced interpretations of the same "concept" within ecology.

**Notes: ** Ontologies within ecology are becoming more common, with three particular trends emerging:

  1. *Domain-specific ontologies* that focus on capturing terminology used in specialized scientific disciplines or communities, for example:
      1. Ontologies in Web Ontology Language (OWL) for food-web networks that are described in Williams 2006 (see Section \@ref(williams2006)).
      2. *Semantic Web for Earth and Environmental Terminology (SWEET)* - Maintained by NASA JPL, use OWL ontologies to improve data integration and access capabilities.
  2. *Framework ontologies* that define general concepts and relationships that others can extend when building domain ontologies, for example:
      1. *Extensible Observation Ontology (OBOE)* -  component of the SEEK project; basic concepts and relationships for describing observational datasets (e.g., field, experimental, simulation and monitoring data). Compatible with EML, and its core concepts (i.e., "Entity", "Characteristic", and "Measurement Standard") can all be extended with domain-specific ontologies.
      2. *Classes for Environmental Data Exchange (CEDEX)* - formal framework for describing monitoring and experimental data from the European consortium of long-term ecological research stations.
      3. *Observations Data Model (ODM)* or the *Open Geospatial Consortium's Observations and Measurements model OGC O&M* - framework intended to facilitate the sharing and reuse of data within particular domains (hydrology projects for the first, geospatial work for the second); free-form extensibility of OBOE is not present.
  3. Other less formal approaches that identify and describe terms and concepts that are relevant to ecological research
    - These commonly exist as thesauri that seek to standardize use of terms (and thus may aid in searching or browsing), but are not as effective as formal ontologies due to informal (and therefore a lack of logical relationships) nature.

The authors provide a nice figure that exemplifies the architectural framework of responsible management and archiving of data:

```{r, echo=FALSE}
knitr::include_graphics(rep("images/madin2008.bmp"))
```

### Reichman, 2011 {#reichman2011}

*"Challenges and opportunities of open data in ecology"* [@reichman2011challenges]

**Key significance:** This piece focuses on how ecology (in some respects) has moved from a site-scale experimental field to one that is capable of large synthesis studies across broad spatial or temporal scales. They discuss issues of heterogeneity in data format and availability, and how to resolve them in order to perform synthetic analyses.

**Key notes: **

Reichman *et al* estimate that just 1% of ecological data that has been produced is available after publication of the associated results.

They note three major technological challenges to "open data" (a la, Michiner, 2006), namely:

  1. Data dispersion - Decentralized existence across a broad range of databases (either local or online)
  2. Heterogeneity - Lack of consistency in collection, formatting and reporting
  3. Provenance - Issues of origin and history (relevant for datasets, as well as data products)
  
*Data dispersion:*
  
  - *DataONE* - A project designed to provide access to a number of central data repositories (e.g., Data Dryad) that facilitates data searching and access (also see *Global Earth Observation System of Systems (GEOSS)*)

*Heterogeneity:*

  - Data heterogeneity unlikely to be resolved due to specific research objectives and logistical constraints. Use of structured metadata such as EML, however, is efficient at aiding access and reporting of heterogeneous data.

*Data provenance:*

  - Need scripted workflows that show quality control, processing and analysis of a dataset, particularly for derived datasets (e.g., meta-analyses or other secondary data objects)
  - Unique identifiers (as DataONE) provides can be key for monitoring data provenance
  
*Social considerations:* Social constraints to formalized sharing and archiving data are likely greater than the technical challenges. A formal reward system for promoting open access data may be key to advancing open data within ecology.


### Wickham, 2014

*"Tidy data"* [@wickham2014tidy]

**Key significance:** A formal description of Hadley's "tidy data" concept. See also this online [article](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html), which is a bit more of a code-based explanation of tidy data.

**Key notes: ** Tidy data has the following fundamental format: each variable is a column, each observation is a row, and each type of observational unit is a table.

*Data tidying* - as organizing datasets such to facilitate analysis

In organizing data, there is a general rule of thumb that it's easier to describe functional relationships between variables (i.e., linear combinations of columns) rather than relationships between observations (rows); AND it's easier to compare across groups of observations (rows) relative to between groups of variables (columns)

There are four basic verbs for data manipulation:

  1. *Filter* - subsetting or removing observations based on a condition
  2. *Transform* - adding or modifying variables
  3. *Aggregate* - collapsing multiple values into a single value
  4. *Sort* - changing the order of observations
  
Tidy data is particularly useful for modeling, and is a large part of why it is designed/promoted.

## Tipping points

### Scheffer, 2001

### Riggs, 2008

### Scheffer, 2009


## Decision-making

### Fischer, 2009

### Chapin, 2010

### Folke, 2010

### Polasky, 2011


## Mangrove thresholds

### Cavanaugh, 2014

### Eslami-Andergoli, 2015

### Ellison, 2015

### Sasmito, 2016
